{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict, Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "from scipy.spatial import distance\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score,recall_score, precision_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задания 1, 2 и 3 реализованы внутри класса Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree():\n",
    "    class Node():\n",
    "        def __init__(self):\n",
    "            self.rule = -1\n",
    "            self.threshold = None\n",
    "            self.left_node = None\n",
    "            self.right_node = None\n",
    "            self.node_class = None\n",
    "            \n",
    "    def __init__(self, debug=''):\n",
    "        self.tree = None\n",
    "        self.debug = debug\n",
    "        self.impurity_f = {\n",
    "            'entropy': self.get_entropy,\n",
    "            'gini': self.get_gini\n",
    "        }\n",
    "    \n",
    "    def get_entropy(self, cnt, n): #Задание 1\n",
    "        entropy = 0\n",
    "        for _, class_n in cnt.most_common():\n",
    "            if class_n > 0:\n",
    "                entropy -= (class_n/n * np.log2(class_n/n))\n",
    "        return entropy\n",
    "    \n",
    "    def get_gini(self, cnt, n):\n",
    "        gini = 0\n",
    "        for _, class_n in cnt.most_common():\n",
    "            gini += class_n/n * (1 - class_n/n)\n",
    "        return gini\n",
    "        \n",
    "    def get_IG_threshold(self, v, y, n, impurity_f):\n",
    "        sorted_vy = sorted(list(zip(v, y)))\n",
    "        best_threshold = None\n",
    "        best_IG = None\n",
    "        y_left_cnt = Counter()\n",
    "        y_right_cnt = Counter([t[1] for t in sorted_vy[0:]])\n",
    "        n_left = 0\n",
    "        n_right = len(sorted_vy)\n",
    "        total_IG = n_right/n * impurity_f(y_right_cnt, n_right) # all values    \n",
    "        for pos, (v, y) in enumerate(sorted_vy):\n",
    "            if pos > 0 and (sorted_vy[pos][0] != sorted_vy[pos-1][0]):\n",
    "                left_IG = n_left/n * impurity_f(y_left_cnt, n_left)\n",
    "                right_IG = n_right/n * impurity_f(y_right_cnt, n_right)\n",
    "                IG = total_IG - left_IG - right_IG\n",
    "                if best_IG is None or IG > best_IG:\n",
    "                    best_IG = IG\n",
    "                    best_threshold = v\n",
    "            y_left_cnt[y] = y_left_cnt[y] + 1\n",
    "            n_left += 1\n",
    "            y_right_cnt[y] -= 1\n",
    "            n_right -= 1\n",
    "        return best_IG, best_threshold\n",
    "    #Задание 2\n",
    "    def build_tree(self, node, X, y, n, level, max_level, impurity):\n",
    "        cnt_y = Counter(y)\n",
    "        if len(cnt_y) == 1:\n",
    "            node.node_class = y[0]\n",
    "            return\n",
    "        if level == max_level:\n",
    "            node.node_class = cnt_y.most_common()[0][0]\n",
    "            return\n",
    "        features_num = X.shape[1]\n",
    "        features2IG = []\n",
    "        for feature in range(0, features_num):\n",
    "            IG, threshold = self.get_IG_threshold(X[:, feature], y, n, self.impurity_f[impurity])\n",
    "            if IG is not None:\n",
    "                features2IG.append((IG, threshold, feature))\n",
    "        if len(features2IG) == 0:\n",
    "            node.node_class = y[0]\n",
    "            return\n",
    "        IG, threshold, best_feature = sorted(features2IG, reverse=True)[0] # get always max\n",
    "        node.IG = IG\n",
    "        node.rule = best_feature\n",
    "        node.threshold = threshold\n",
    "        if 'v' in self.debug:\n",
    "            print(f\"[L{level}] n: {X.shape[0]}, feature: {node.rule}, threshold: {node.threshold}, IG: {IG}\")\n",
    "        \n",
    "        # Left subtree\n",
    "        node.left_node = self.Node()\n",
    "        if 'vvv' in self.debug:\n",
    "            print(f\"[L{level}] Samples to left: {X[X[:, best_feature] < threshold].shape[0]}\")\n",
    "        self.build_tree(node.left_node,\n",
    "                        X[X[:, best_feature] < threshold],\n",
    "                        y[X[:, best_feature] < threshold],\n",
    "                        n, level+1, max_level, impurity)\n",
    "        # Right subtree\n",
    "        node.right_node = self.Node()\n",
    "        if 'vvv' in self.debug:\n",
    "            print(f\"[L{level}] Samples to right: {X[X[:, best_feature] >= threshold].shape[0]}\")\n",
    "        self.build_tree(node.right_node,\n",
    "                        X[X[:, best_feature] >= threshold],\n",
    "                        y[X[:, best_feature] >= threshold],\n",
    "                        n, level+1, max_level, impurity) \n",
    "        return\n",
    "        \n",
    "    \n",
    "    def fit(self, X, y, max_level=10, impurity='entropy'):\n",
    "        self.tree = self.Node()\n",
    "        self.build_tree(self.tree, X, y, X.shape[0], 0, max_level, impurity)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        predictions = []\n",
    "        for sample in X:\n",
    "            current_node = self.tree\n",
    "            while current_node.node_class is None:\n",
    "                if sample[current_node.rule] < current_node.threshold:\n",
    "                    current_node = current_node.left_node\n",
    "                else:\n",
    "                    current_node = current_node.right_node\n",
    "            predictions.append(current_node.node_class)\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spam dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_df = pd.read_csv('spam.csv')\n",
    "X = spam_df[spam_df.columns.difference(['label'])]\n",
    "y = spam_df.label.values\n",
    "spam_X_train, spam_X_val, spam_y_train, spam_y_val = train_test_split(X, y, test_size=0.2, random_state=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spam dataset, impurity: entropy\n",
      "----------\n",
      "Depth: 1, accuracy: 0.7839305103148752, recall: 0.5266106442577031, precision: 0.8623853211009175\n",
      "Depth: 2, accuracy: 0.8230184581976113, recall: 0.8627450980392157, precision: 0.7298578199052133\n",
      "Depth: 3, accuracy: 0.8914223669923995, recall: 0.7871148459383753, precision: 0.921311475409836\n",
      "Depth: 4, accuracy: 0.9153094462540716, recall: 0.8375350140056023, precision: 0.9373040752351097\n",
      "Depth: 5, accuracy: 0.9229098805646037, recall: 0.8711484593837535, precision: 0.9255952380952381\n",
      "Depth: 6, accuracy: 0.9337676438653637, recall: 0.8711484593837535, precision: 0.9539877300613497\n",
      "Depth: 7, accuracy: 0.9294245385450597, recall: 0.8907563025210085, precision: 0.9244186046511628\n",
      "Depth: 8, accuracy: 0.9196525515743756, recall: 0.8543417366946778, precision: 0.9327217125382263\n",
      "Depth: 9, accuracy: 0.9294245385450597, recall: 0.8627450980392157, precision: 0.9506172839506173\n",
      "Depth: 10, accuracy: 0.9109663409337676, recall: 0.865546218487395, precision: 0.9008746355685131\n",
      "----------\n",
      "Best tree depth: 6, accuracy: 0.9337676438653637\n"
     ]
    }
   ],
   "source": [
    "impurity = 'entropy'\n",
    "print(f\"Spam dataset, impurity: {impurity}\")\n",
    "print('-' * 10)\n",
    "best_depth = None\n",
    "best_accuracy = None\n",
    "dtree = DecisionTree(debug='')\n",
    "for max_level in range(1, 11):\n",
    "    dtree.fit(spam_X_train.values, spam_y_train, max_level=max_level, impurity=impurity)\n",
    "    predictions = dtree.predict(spam_X_val.values)\n",
    "    accuracy = accuracy_score(spam_y_val, predictions)\n",
    "    recall = recall_score(spam_y_val, predictions)\n",
    "    precision= precision_score(spam_y_val, predictions)\n",
    "    if best_accuracy is None or accuracy > best_accuracy:\n",
    "        best_depth = max_level\n",
    "        best_accuracy = accuracy\n",
    "    print(f\"Depth: {max_level}, accuracy: {accuracy}, recall: {recall}, precision: {precision}\")\n",
    "print('-' * 10)\n",
    "print(f\"Best tree depth: {best_depth}, accuracy: {best_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spam dataset, impurity: gini\n",
      "----------\n",
      "Depth: 1, accuracy: 0.7839305103148752, recall: 0.5266106442577031, precision: 0.8623853211009175\n",
      "Depth: 2, accuracy: 0.8783930510314875, recall: 0.7282913165266106, precision: 0.9454545454545454\n",
      "Depth: 3, accuracy: 0.8870792616720955, recall: 0.834733893557423, precision: 0.8688046647230321\n",
      "Depth: 4, accuracy: 0.9077090119435396, recall: 0.8123249299719888, precision: 0.9415584415584416\n",
      "Depth: 5, accuracy: 0.9044516829533116, recall: 0.8543417366946778, precision: 0.8944281524926686\n",
      "Depth: 6, accuracy: 0.9196525515743756, recall: 0.8515406162464986, precision: 0.9353846153846154\n",
      "Depth: 7, accuracy: 0.9087947882736156, recall: 0.8543417366946778, precision: 0.9050445103857567\n",
      "Depth: 8, accuracy: 0.9229098805646037, recall: 0.8571428571428571, precision: 0.9386503067484663\n",
      "Depth: 9, accuracy: 0.9174809989142236, recall: 0.865546218487395, precision: 0.9169139465875371\n",
      "Depth: 10, accuracy: 0.9218241042345277, recall: 0.8739495798319328, precision: 0.9203539823008849\n",
      "----------\n",
      "Best tree depth: 8, accuracy: 0.9229098805646037\n"
     ]
    }
   ],
   "source": [
    "impurity = 'gini'\n",
    "print(f\"Spam dataset, impurity: {impurity}\")\n",
    "print('-' * 10)\n",
    "best_depth = None\n",
    "best_accuracy = None\n",
    "dtree = DecisionTree(debug='')\n",
    "for max_level in range(1, 11):\n",
    "    dtree.fit(spam_X_train.values, spam_y_train, max_level=max_level, impurity=impurity)\n",
    "    predictions = dtree.predict(spam_X_val.values)\n",
    "    accuracy = accuracy_score(spam_y_val, predictions)\n",
    "    recall = recall_score(spam_y_val, predictions)\n",
    "    precision= precision_score(spam_y_val, predictions)\n",
    "    if best_accuracy is None or accuracy > best_accuracy:\n",
    "        best_depth = max_level\n",
    "        best_accuracy = accuracy\n",
    "    print(f\"Depth: {max_level}, accuracy: {accuracy}, recall: {recall}, precision: {precision}\")\n",
    "print('-' * 10)\n",
    "print(f\"Best tree depth: {best_depth}, accuracy: {best_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of neighbours: 1, accuracy: 0.9077090119435396, recall: 0.8851540616246498, precision: 0.8777777777777778\n",
      "Number of neighbours: 2, accuracy: 0.9022801302931596, recall: 0.7983193277310925, precision: 0.9405940594059405\n",
      "Number of neighbours: 3, accuracy: 0.9109663409337676, recall: 0.8683473389355743, precision: 0.8985507246376812\n",
      "Number of neighbours: 4, accuracy: 0.9066232356134636, recall: 0.8151260504201681, precision: 0.9356913183279743\n",
      "Number of neighbours: 5, accuracy: 0.9131378935939196, recall: 0.8571428571428571, precision: 0.9134328358208955\n",
      "Number of neighbours: 6, accuracy: 0.9066232356134636, recall: 0.8263305322128851, precision: 0.9247648902821317\n",
      "Number of neighbours: 7, accuracy: 0.9163952225841476, recall: 0.8683473389355743, precision: 0.9117647058823529\n",
      "Number of neighbours: 8, accuracy: 0.9055374592833876, recall: 0.834733893557423, precision: 0.9141104294478528\n",
      "Number of neighbours: 9, accuracy: 0.9109663409337676, recall: 0.8683473389355743, precision: 0.8985507246376812\n",
      "Number of neighbours: 10, accuracy: 0.9066232356134636, recall: 0.8375350140056023, precision: 0.9143730886850153\n",
      "----------\n",
      "Best number of neighbours: 7, accuracy: 0.9163952225841476\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "spam_X_train = scaler.fit_transform(spam_X_train)\n",
    "spam_X_val = scaler.fit_transform(spam_X_val)\n",
    "best_number_of_neigbours = None\n",
    "best_accuracy = None\n",
    "for k in range(1, 11):\n",
    "    classifier= KNeighborsClassifier(n_neighbors=k, algorithm='kd_tree')\n",
    "    classifier.fit(spam_X_train, spam_y_train)\n",
    "    predictions = classifier.predict(spam_X_val)\n",
    "    accuracy = accuracy_score(spam_y_val, predictions)\n",
    "    recall = recall_score(spam_y_val, predictions)\n",
    "    precision= precision_score(spam_y_val, predictions)\n",
    "    print(f\"Number of neighbours: {k}, accuracy: {accuracy}, recall: {recall}, precision: {precision}\")\n",
    "    if best_accuracy is None or accuracy > best_accuracy:\n",
    "        best_number_of_neighbours = k\n",
    "        best_accuracy = accuracy\n",
    "print('-' * 10)\n",
    "print(f\"Best number of neighbours: {best_number_of_neighbours}, accuracy: {best_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cancer dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer_df = pd.read_csv('cancer.csv')\n",
    "cancer_df['int_label'] = cancer_df.label.map({'M':1, 'B':0})\n",
    "cancer_df['label'] = cancer_df.int_label\n",
    "cancer_df.drop('int_label', axis=1, inplace=True)\n",
    "X = cancer_df[cancer_df.columns.difference(['label'])]\n",
    "y = cancer_df.label.values\n",
    "cancer_X_train, cancer_X_val, cancer_y_train, cancer_y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cancer dataset, impurity: entropy\n",
      "----------\n",
      "Depth: 1, accuracy: 0.868421052631579, recall: 0.8095238095238095, precision: 0.8292682926829268\n",
      "Depth: 2, accuracy: 0.868421052631579, recall: 0.8095238095238095, precision: 0.8292682926829268\n",
      "Depth: 3, accuracy: 0.9122807017543859, recall: 0.8809523809523809, precision: 0.8809523809523809\n",
      "Depth: 4, accuracy: 0.956140350877193, recall: 0.8809523809523809, precision: 1.0\n",
      "Depth: 5, accuracy: 0.9122807017543859, recall: 0.7619047619047619, precision: 1.0\n",
      "Depth: 6, accuracy: 0.9473684210526315, recall: 0.8571428571428571, precision: 1.0\n",
      "Depth: 7, accuracy: 0.9473684210526315, recall: 0.8571428571428571, precision: 1.0\n",
      "Depth: 8, accuracy: 0.9473684210526315, recall: 0.8571428571428571, precision: 1.0\n",
      "Depth: 9, accuracy: 0.9473684210526315, recall: 0.8571428571428571, precision: 1.0\n",
      "Depth: 10, accuracy: 0.9473684210526315, recall: 0.8571428571428571, precision: 1.0\n",
      "----------\n",
      "Best tree depth: 4, accuracy: 0.956140350877193\n"
     ]
    }
   ],
   "source": [
    "impurity = 'entropy'\n",
    "print(f\"Cancer dataset, impurity: {impurity}\")\n",
    "print('-' * 10)\n",
    "best_depth = None\n",
    "best_accuracy = None\n",
    "dtree = DecisionTree(debug='')\n",
    "for max_level in range(1, 11):\n",
    "    dtree.fit(cancer_X_train.values, cancer_y_train, max_level=max_level, impurity=impurity)\n",
    "    predictions = dtree.predict(cancer_X_val.values)\n",
    "    accuracy = accuracy_score(cancer_y_val, predictions)\n",
    "    recall = recall_score(cancer_y_val, predictions)\n",
    "    precision= precision_score(cancer_y_val, predictions)\n",
    "    if best_accuracy is None or accuracy > best_accuracy:\n",
    "        best_depth = max_level\n",
    "        best_accuracy = accuracy\n",
    "    print(f\"Depth: {max_level}, accuracy: {accuracy}, recall: {recall}, precision: {precision}\")\n",
    "print('-' * 10)\n",
    "print(f\"Best tree depth: {best_depth}, accuracy: {best_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cancer dataset, impurity: gini\n",
      "----------\n",
      "Depth: 1, accuracy: 0.8771929824561403, recall: 0.7857142857142857, precision: 0.868421052631579\n",
      "Depth: 2, accuracy: 0.8859649122807017, recall: 0.7857142857142857, precision: 0.8918918918918919\n",
      "Depth: 3, accuracy: 0.9210526315789473, recall: 0.8571428571428571, precision: 0.9230769230769231\n",
      "Depth: 4, accuracy: 0.9298245614035088, recall: 0.8333333333333334, precision: 0.9722222222222222\n",
      "Depth: 5, accuracy: 0.9298245614035088, recall: 0.8333333333333334, precision: 0.9722222222222222\n",
      "Depth: 6, accuracy: 0.9298245614035088, recall: 0.8333333333333334, precision: 0.9722222222222222\n",
      "Depth: 7, accuracy: 0.9298245614035088, recall: 0.8333333333333334, precision: 0.9722222222222222\n",
      "Depth: 8, accuracy: 0.9298245614035088, recall: 0.8333333333333334, precision: 0.9722222222222222\n",
      "Depth: 9, accuracy: 0.9298245614035088, recall: 0.8333333333333334, precision: 0.9722222222222222\n",
      "Depth: 10, accuracy: 0.9298245614035088, recall: 0.8333333333333334, precision: 0.9722222222222222\n",
      "----------\n",
      "Best tree depth: 4, accuracy: 0.9298245614035088\n"
     ]
    }
   ],
   "source": [
    "impurity = 'gini'\n",
    "print(f\"Cancer dataset, impurity: {impurity}\")\n",
    "print('-' * 10)\n",
    "best_depth = None\n",
    "best_accuracy = None\n",
    "dtree = DecisionTree(debug='')\n",
    "for max_level in range(1, 11):\n",
    "    dtree.fit(cancer_X_train.values, cancer_y_train, max_level=max_level, impurity=impurity)\n",
    "    predictions = dtree.predict(cancer_X_val.values)\n",
    "    accuracy = accuracy_score(cancer_y_val, predictions)\n",
    "    recall = recall_score(cancer_y_val, predictions)\n",
    "    precision= precision_score(cancer_y_val, predictions)\n",
    "    if best_accuracy is None or accuracy > best_accuracy:\n",
    "        best_depth = max_level\n",
    "        best_accuracy = accuracy\n",
    "    print(f\"Depth: {max_level}, accuracy: {accuracy}, recall: {recall}, precision: {precision}\")\n",
    "print('-' * 10)\n",
    "print(f\"Best tree depth: {best_depth}, accuracy: {best_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of neighbours: 1, accuracy: 0.9210526315789473, recall: 0.9047619047619048, precision: 0.8837209302325582\n",
      "Number of neighbours: 2, accuracy: 0.9385964912280702, recall: 0.8571428571428571, precision: 0.972972972972973\n",
      "Number of neighbours: 3, accuracy: 0.9473684210526315, recall: 0.9047619047619048, precision: 0.95\n",
      "Number of neighbours: 4, accuracy: 0.956140350877193, recall: 0.8809523809523809, precision: 1.0\n",
      "Number of neighbours: 5, accuracy: 0.9473684210526315, recall: 0.8809523809523809, precision: 0.9736842105263158\n",
      "Number of neighbours: 6, accuracy: 0.956140350877193, recall: 0.8809523809523809, precision: 1.0\n",
      "Number of neighbours: 7, accuracy: 0.9298245614035088, recall: 0.8809523809523809, precision: 0.925\n",
      "Number of neighbours: 8, accuracy: 0.9473684210526315, recall: 0.8809523809523809, precision: 0.9736842105263158\n",
      "Number of neighbours: 9, accuracy: 0.9385964912280702, recall: 0.9047619047619048, precision: 0.926829268292683\n",
      "Number of neighbours: 10, accuracy: 0.956140350877193, recall: 0.9047619047619048, precision: 0.9743589743589743\n",
      "----------\n",
      "Best number of neighbours: 4, accuracy: 0.956140350877193\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "cancer_X_train = scaler.fit_transform(cancer_X_train)\n",
    "cancer_X_val = scaler.fit_transform(cancer_X_val)\n",
    "best_number_of_neigbours = None\n",
    "best_accuracy = None\n",
    "for k in range(1, 11):\n",
    "    classifier= KNeighborsClassifier(n_neighbors=k, algorithm='kd_tree')\n",
    "    classifier.fit(cancer_X_train, cancer_y_train)\n",
    "    predictions = classifier.predict(cancer_X_val)\n",
    "    accuracy = accuracy_score(cancer_y_val, predictions)\n",
    "    recall = recall_score(cancer_y_val, predictions)\n",
    "    precision= precision_score(cancer_y_val, predictions)\n",
    "    print(f\"Number of neighbours: {k}, accuracy: {accuracy}, recall: {recall}, precision: {precision}\")\n",
    "    if best_accuracy is None or accuracy > best_accuracy:\n",
    "        best_number_of_neighbours = k\n",
    "        best_accuracy = accuracy\n",
    "print('-' * 10)\n",
    "print(f\"Best number of neighbours: {best_number_of_neighbours}, accuracy: {best_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом, лучше всего для обоих случаев работает decision tree с impurity=entropy. (В случае с датасетом Cancer данная модель работает так же хорошо, как и kNN). Думаю, это происходит потому, что Decision tree поддерживает взаимодействие между объектами в ходе классификации. Энтропия считается сложнее и более \"глубоко\" работает с данными, думаю поэтому думаю она дает несколько лучшие результаты. Однако, хочется отметить, что результаты работы классификаторов очень близки и на практике скорее всего будет выбран decision tree с gini потому, что у этого классификатора самая маленькая вычислительная сложность. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
