{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kNN & Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Суммарное количество баллов: 10 + 3 bonus__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kNN, рак и спам\n",
    "\n",
    "В этом части домашнего задания Вам предлагается при помощи классификации методом k ближайших соседей научиться отличать тип опухоли в организме, а так же определять сообщения со спамом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import copy\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 1 (1 балл)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. (0.5 балла)\n",
    "Реализуйте методы `read_cancer_dataset` и `read_spam_dataset`. Каждый из них принимает на вход путь к набору данных и возвращает выборку `X` и соответствующие метки `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_open = pd.read_csv(\"cancer.csv\")\n",
    "data = data_open.loc [1:10000] \n",
    "X_cancer = data[data.columns.difference(['label'])].values\n",
    "y_cancer = data.label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_open = pd.read_csv(\"spam.csv\")\n",
    "data = data_open.loc [1:10000] \n",
    "X_spam = data[data.columns.difference(['label'])].values\n",
    "y_spam = data.label.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. (0.5 балла) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Начиная работать с данными, нам необходимо их предобработать и подготовить. В частности, нам необходимо разделить выборку на две: тренировочную и тестовую. Тренировочная выборка необходима для обучения алгоритма, а тестовая для проверки результатов обучения. Обычно используют коэффициент разделения `0.9`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(data, ratio):\n",
    "    train = data.sample(frac = ratio, random_state = 200)\n",
    "    test = data.drop(train.index)\n",
    "    return train, test\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 2 (1.5 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также прежде чем приступать к решению задачи, нам необходимо определиться с метриками, которые позволят нам оценить полученное решение. Для задач классификации мы можем использовать precision, recall и accuracy. Эти метрики считаются для каждого класса. \n",
    "\n",
    "__Precision__ отражает то, насколько редко мы ошибаемся, когда говорим, что объект пренадлежит к классу. \n",
    "\n",
    "__Recall__ же отражает то, насколько редко классификатор неправильно классифицирует объекты данного класса.\n",
    "\n",
    "__Accuracy__ отражает то, какую часть выборки классификатор отнес к правильному классу."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_precision_recall_accuracy(y_pred, y_true):\n",
    "    tp, tn, fp, fn = 0, 0, 0, 0\n",
    "    for i in range(len(y_true)):\n",
    "        if y_true[i] == y_pred[i] and y_true[i] == 1:\n",
    "            tp += 1\n",
    "        elif y_true[i] == y_pred[i] and y_true[i] == 0:\n",
    "            tn += 1\n",
    "        elif y_true[i] != y_pred[i] and y_true[i] == 0:\n",
    "            fp += 1\n",
    "        else:\n",
    "            fn += 1\n",
    "    precision=tp/(tp+fp)\n",
    "    recall=tp/(tp+fn)\n",
    "    accuracy = (tn + tp)/(tn + tp + fp + fn)\n",
    "    return precision, recall, accuracy\n",
    "    \n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь, имея этот метод, мы можем построить кривые зависимости Precision, Recall и Accuracy от параметра `k`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_precision_recall(X_train, y_train, X_test, y_test, max_k=30):\n",
    "    ks = list(range(1, max_k + 1))\n",
    "    classes = len(np.unique(list(y_train) + list(y_test)))\n",
    "    precisions = [[] for _ in range(classes)]\n",
    "    recalls = [[] for _ in range(classes)]\n",
    "    accuracies = []\n",
    "    for k in ks:\n",
    "        classifier = KNearest(k)\n",
    "        classifier.fit(X_train, y_train)\n",
    "        y_pred = classifier.predict(X_test)\n",
    "        precision, recall, acc = get_precision_recall_accuracy(y_pred, y_test)\n",
    "        for c in range(classes):\n",
    "            precisions[c].append(precision[c])\n",
    "            recalls[c].append(recall[c])\n",
    "        accuracies.append(acc)\n",
    "    def plot(x, ys, ylabel, legend=True):        \n",
    "        plt.figure(figsize = (12, 3))\n",
    "        plt.xlabel(\"K\")\n",
    "        plt.ylabel(ylabel)\n",
    "        plt.xlim(x[0], x[-1])\n",
    "        plt.ylim(np.min(ys)-0.01, np.max(ys)+0.01)\n",
    "        for cls, cls_y in enumerate(ys):\n",
    "            plt.plot(x, cls_y, label=\"Class \" + str(cls))\n",
    "        if legend:\n",
    "            plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    plot(ks, recalls, \"Recall\")\n",
    "    plot(ks, precisions, \"Precision\")\n",
    "    plot(ks, [accuracies], \"Accuracy\", legend=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также для оценки качества классификации построим __ROC-кривую__. Она отражает зависимость __True Positive Rate__ (TPR) от __False Positive Rate__ (FPR) для заранее фиксированного класса. Чем график выше побочной диагонали - тем лучше."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve(X_train, y_train, X_test, y_test, max_k=30):\n",
    "    positive_samples = sum(1 for y in y_test if y == 0)\n",
    "    ks = list(range(1, max_k + 1))\n",
    "    curves_tpr = []\n",
    "    curves_fpr = []\n",
    "    colors = []\n",
    "    for k in ks:\n",
    "        colors.append([k / ks[-1], 0, 1 - k / ks[-1]])\n",
    "        knearest = KNearest(k)\n",
    "        knearest.fit(X_train, y_train)\n",
    "        p_pred = [p[0] for p in knearest.predict_proba(X_test)]\n",
    "        tpr = []\n",
    "        fpr = []\n",
    "        for w in np.arange(-0.01, 1.02, 0.01):\n",
    "            y_pred = [(0 if p > w else 1) for p in p_pred]\n",
    "            tpr.append(sum(1 for yp, yt in zip(y_pred, y_test) if yp == 0 and yt == 0) / positive_samples)\n",
    "            fpr.append(sum(1 for yp, yt in zip(y_pred, y_test) if yp == 0 and yt != 0) / (len(y_test) - positive_samples))\n",
    "        curves_tpr.append(tpr)\n",
    "        curves_fpr.append(fpr)\n",
    "    plt.figure(figsize = (7, 7))\n",
    "    for tpr, fpr, c in zip(curves_tpr, curves_fpr, colors):\n",
    "        plt.plot(fpr, tpr, color=c)\n",
    "    plt.plot([0, 1], [0, 1], linestyle=\"--\")\n",
    "    plt.xlabel(\"False positive rate\")\n",
    "    plt.ylabel(\"True positive rate\")\n",
    "    plt.xlim(-0.01, 1.01)\n",
    "    plt.ylim(-0.01, 1.01)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 3  (3 балла)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. (2 балла)\n",
    "Осталось реализовать сам классификатор. Реализуйте его, используя KD-дерево. (При желании можно воспользоваться библиотечной реализацией дерева)\n",
    "\n",
    "Метод `__init__` принимает на вход количество соседей, по которым предсказывается класс, и размер листьев KD-дерева.\n",
    "\n",
    "Метод `fit` должен по набору данных и меток \"обучать\" классификатор. \n",
    "\n",
    "Метод `predict_proba` должен предсказывать вероятности классов для заданного набора данных основываясь на классах соседей"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
